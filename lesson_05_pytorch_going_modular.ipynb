{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "255f730b",
   "metadata": {},
   "source": [
    "### 05 - PyTorch going modular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d2c542",
   "metadata": {},
   "source": [
    "Going from notebooks to scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aaa52a",
   "metadata": {},
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1585404a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\pizza_steak_sushi directory already exists, skipping download...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# setup path for data folder\n",
    "data_path = Path('data')\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# If the image folder doesn't exist, download and extract the data\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory already exists, skipping download...\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    # Download pizza, steak and sushi data\n",
    "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "        print(f\"Downloading {len(request.content)} MB of data for pizza, steak and sushi images...\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    # Unzip the downloaded file\n",
    "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(image_path)\n",
    "        print(f\"Unzipped pizza, steak and sushi data to {image_path}\")\n",
    "\n",
    "    # Remove the zip file\n",
    "    os.remove(data_path / \"pizza_steak_sushi.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f432b012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/data_setup.py\n",
    "\"\"\"\n",
    "Contains functionality for creating PyTorch DataLoaders for\n",
    "image classification data\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "def create_dataloaders(train_dir: str, \n",
    "                       test_dir: str, \n",
    "                       transform: transforms.Compose, \n",
    "                       batch_size: int, \n",
    "                       num_workers: int = NUM_WORKERS):\n",
    "    \"\"\"\n",
    "    Creates training and testing DataLoaders.\n",
    "\n",
    "    Takes in training and testing directory paths and turns them into PyTorch\n",
    "    Datasets and then into DataLoaders.\n",
    "\n",
    "    Args:\n",
    "        train_dir: Path to training directory.\n",
    "        test_dir: Path to testing directory.\n",
    "        transform: torchvision.transforms.Compose containing transformations to perform on data.\n",
    "        batch_size: Number of samples per batch of data.\n",
    "        num_workers: Number of workers for DataLoader to use.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of (train_dataloader, test_dataloader, class_names).\n",
    "    \"\"\"\n",
    "    train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "    test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
    "    class_names = train_data.classes\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a79fae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/model_builder.py\n",
    "\"\"\"\n",
    "Contains PyTorch model code to instantiate a TinyVGG model\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Creates a TinyVGG model.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_shape: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.convblock1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, out_channels=hidden_shape, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_shape, out_channels=hidden_shape, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        )\n",
    "        self.convblock2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_shape, out_channels=hidden_shape, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_shape, out_channels=hidden_shape, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_shape * 16 * 16, out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convblock1(x)\n",
    "        x = self.convblock2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f781dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/engine.py\n",
    "\"\"\"\n",
    "Contains functions for training and testing a PyTorch model\n",
    "\"\"\"\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "def train_step(model: torch.nn.Module, \n",
    "                dataloader: torch.utils.data.DataLoader, \n",
    "                loss_fn: torch.nn.Module, \n",
    "                optimizer: torch.optim.Optimizer, \n",
    "                device: str) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Trains a PyTorch model for a single epoch.\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model to be trained.\n",
    "        dataloader: A DataLoader containing the training data.\n",
    "        loss_fn: A loss function to compute the loss.\n",
    "        optimizer: An optimizer to update the model's parameters.\n",
    "        device: The device to use for training (e.g., \"cuda\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "        A tuple of (train_loss, train_accuracy).\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_pred_class = torch.argmax(y_pred, dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item()\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader.dataset)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module, \n",
    "              device: str) -> Tuple[float, float]:\n",
    "    \"\"\" Tests a PyTorch model for a single epoch.\n",
    "    Args:\n",
    "        model: A PyTorch model to be tested.\n",
    "        dataloader: A DataLoader containing the testing data.\n",
    "        loss_fn: A loss function to compute the loss.\n",
    "        device: The device to use for testing (e.g., \"cuda\" or \"cpu\").\n",
    "    Returns:\n",
    "        A tuple of (test_loss, test_accuracy).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            y_pred_class = torch.argmax(y_pred, dim=1)\n",
    "            test_acc += (y_pred_class == y).sum().item()\n",
    "    test_loss /= len(dataloader)\n",
    "    test_acc /= len(dataloader.dataset)\n",
    "    return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "        train_dataloader: torch.utils.data.DataLoader, \n",
    "        test_dataloader: torch.utils.data.DataLoader, \n",
    "        optimizer_fn: torch.nn.Module, \n",
    "        loss_fn: torch.optim.Optimizer, \n",
    "        epochs: int, \n",
    "        device: str) -> Dict[str, List[float]]:\n",
    "    \"\"\" Trains and tests a PyTorch model for a specified number of epochs.\n",
    "    Args:\n",
    "        model: A PyTorch model to be trained and tested.\n",
    "        train_dataloader: A DataLoader containing the training data.\n",
    "        test_dataloader: A DataLoader containing the testing data.\n",
    "        loss_fn: A loss function to compute the loss.\n",
    "        optimizer: An optimizer to update the model's parameters.\n",
    "        epochs: The number of epochs to train the model for.\n",
    "        device: The device to use for training and testing (e.g., \"cuda\" or \"cpu\").\n",
    "    Returns:\n",
    "        A dictionary of training and testing losses and accuracies.\n",
    "    \"\"\"\n",
    "    results = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model, train_dataloader, loss_fn, optimizer, device)\n",
    "        test_loss, test_acc = test_step(model, test_dataloader, loss_fn, device)\n",
    "        print(f\"Epoch: {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "    \n",
    "        print(\n",
    "            f\"Epoch: {epoch+1}/{epochs} | \"\n",
    "            f\"Train Loss: {train_loss:.4f} | \"\n",
    "            f\"Train Acc: {train_acc:.4f} | \"\n",
    "            f\"Test Loss: {test_loss:.4f} | \"\n",
    "            f\"Test Acc: {test_acc:.4f}\"\n",
    "            \n",
    "        )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dea8c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/utils.py\n",
    "\"\"\"\n",
    "Contains utility functions for saving and loading models\n",
    "\"\"\"\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def save_model(model: torch.nn.Module, \n",
    "              target_dir: str, \n",
    "              model_name: str):\n",
    "    \"\"\"\n",
    "    Saves a PyTorch model to a target directory.\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model to be saved.\n",
    "        target_dir: The directory to save the model to.\n",
    "        model_name: The name of the model file.\n",
    "    \"\"\"\n",
    "    target_dir_path = Path(target_dir)\n",
    "    target_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    model_path = target_dir_path / model_name\n",
    "    print(f\"Saving model to {model_path}\")\n",
    "    torch.save(obj=model.state_dict(), f=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9820061e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/train.py\n",
    "\"\"\"\n",
    "Trains a PyTorch model using device agnostic code\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "from torchvision import transforms\n",
    "import datasetup, engine, model_builder, utils\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser.add_argument(\"--num_epochs\", type=int, default=NUM_EPOCHS, help=\"Number of epochs to train the model for\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=BATCH_SIZE, help=\"Batch size for training and testing\")\n",
    "    parser.add_argument(\"--hidden_units\", type=int, default=HIDDEN_UNITS, help=\"Number of hidden units in the model\")\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=LEARNING_RATE, help=\"Learning rate for the optimizer\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Update hyperparameters based on command line arguments\n",
    "    NUM_EPOCHS = args.num_epochs\n",
    "    BATCH_SIZE = args.batch_size\n",
    "    HIDDEN_UNITS = args.hidden_units\n",
    "    LEARNING_RATE = args.learning_rate\n",
    "    # Setup directories\n",
    "    train_dir = \"data/pizza_steak_sushi/train\"\n",
    "    test_dir = \"data/pizza_steak_sushi/test\"\n",
    "    # Setup device-agnostic code\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # Setup transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    # Create DataLoaders\n",
    "    train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "        train_dir=train_dir,\n",
    "        test_dir=test_dir,\n",
    "        transform=transform,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    # Setup model\n",
    "    model = model_builder.TinyVGG(\n",
    "        input_shape=3,\n",
    "        hidden_shape=HIDDEN_UNITS,\n",
    "        output_shape=len(class_names)\n",
    "    ).to(device)\n",
    "\n",
    "    # Setup loss, optimizer\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    # Train the model\n",
    "    results = engine.train(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        device=device\n",
    "    )\n",
    "    # Save the model\n",
    "    utils.save_model(\n",
    "        model=model,\n",
    "        target_dir=\"models\",\n",
    "        model_name=\"tinyvgg_model.pth\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f155ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/predict.py\n",
    "\"\"\"\n",
    "Predicts the class of an image using a pre-trained PyTorch model\n",
    "\"\"\"\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from model_builder import TinyVGG\n",
    "from utils import save_model\n",
    "from pathlib import Path\n",
    "\n",
    "def predict(image_path: str, model_path: str, class_names: list):\n",
    "    \"\"\"\n",
    "    Predicts the class of an image using a pre-trained PyTorch model.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the image to predict.\n",
    "        model_path: Path to the pre-trained model.\n",
    "        class_names: List of class names.\n",
    "    \"\"\"\n",
    "    # Load the model\n",
    "    model = TinyVGG(input_shape=3, hidden_shape=10, output_shape=len(class_names))\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    # Setup transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Load and transform the image\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image).unsqueeze(0)\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(image)\n",
    "        y_pred_class = torch.argmax(y_pred, dim=1)\n",
    "        predicted_class = class_names[y_pred_class.item()]\n",
    "        print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c06dda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
